# Unified Explainable AI Platform

A multi-modal classification platform with Explainable AI (XAI) capabilities for both audio deepfake detection and lung cancer detection from chest X-rays.

## ğŸ‘¥ Team Information

- **Group Members:** Rodolphe BIELEU, Sascha CAUCHON
- **TD Group:** DIA2

---

## ğŸ“‹ Project Overview

This project integrates two existing XAI systems into a single interactive platform:

1. **Deepfake Audio Detection:** Detects real vs. fake audio using neural networks (VGG16, MobileNet, ResNet50, InceptionV3) trained on mel spectrograms from the Fake-or-Real (FoR) dataset.

2. **Lung Cancer Detection:** Detects malignant tumors in chest X-rays using AlexNet and DenseNet121 with transfer learning.

### Key Features

- ğŸµ **Multi-modal Input:** Support for audio (.wav) and image (.png, .jpg) files
- ğŸ¤– **Multiple Models:** 4 audio models + 2 image models
- ğŸ” **XAI Techniques:** LIME, Grad-CAM, and SHAP implementations
- âš¡ **Automatic Filtering:** XAI methods filtered based on input type
- ğŸ“Š **Comparison View:** Side-by-side XAI technique comparison
- ğŸ¨ **User-friendly Interface:** Clean Streamlit-based UI

---

## ğŸ› ï¸ Setup and Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager
- Virtual environment (recommended)

### Installation Steps

1. **Clone the repository:**
   ```bash
   cd genai
   ```

2. **Create a virtual environment (recommended):**
   ```bash
   python -m venv venv
   
   # On Windows:
   venv\Scripts\activate
   
   # On macOS/Linux:
   source venv/bin/activate
   ```

3. **Install dependencies:**
   ```bash
   cd UnifiedXAI
   pip install -r requirements.txt
   ```

4. **Verify installation:**
   ```bash
   python -c "import streamlit; import tensorflow; import lime; import shap; print('All packages installed successfully!')"
   ```

---

## ğŸš€ Running the Application

### Start the Streamlit App

```bash
cd c:\Users\cs202910\Documents\genai\UnifiedXAI
streamlit run app.py
```

The application will open in your default web browser at `http://localhost:8501`

### Using the Interface

1. **Analysis Tab:**
   - Upload an audio (.wav) or image (.png, .jpg) file
   - The system automatically detects the input type
   - Select a compatible classification model
   - Choose an XAI technique
   - Click "Run Analysis" to see results

2. **Comparison Tab:**
   - After running an analysis, switch to this tab
   - Select multiple XAI techniques to compare
   - View side-by-side explanations

3. **About Tab:**
   - Project information and documentation

---

## ğŸ“ Project Structure

```
UnifiedXAI/
â”œâ”€â”€ app.py                 # Main Streamlit application
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ README.md             # This file
â”‚
â”œâ”€â”€ models/               # Classification models
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ audio_models.py   # VGG16, MobileNet, ResNet50, InceptionV3
â”‚   â””â”€â”€ image_models.py   # AlexNet, DenseNet121
â”‚
â”œâ”€â”€ xai/                  # XAI implementations
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ lime_explainer.py # LIME implementation
â”‚   â”œâ”€â”€ gradcam.py        # Grad-CAM implementation
â”‚   â””â”€â”€ shap_explainer.py # SHAP implementation
â”‚
â”œâ”€â”€ utils/                # Utility functions
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ audio_utils.py    # Audio processing (spectrogram conversion)
â”‚   â”œâ”€â”€ image_utils.py    # Image preprocessing
â”‚   â””â”€â”€ compatibility.py  # Model/XAI compatibility registry
â”‚
â””â”€â”€ temp_files/           # Temporary file storage (created at runtime)
```

---

## ğŸ¤– Available Models

### Audio Classification (Deepfake Detection)

| Model | Description | Input Size |
|-------|-------------|------------|
| VGG16 | Transfer learning from ImageNet | 224Ã—224Ã—3 |
| MobileNet | Lightweight, efficient (best accuracy: 91.5%) | 224Ã—224Ã—3 |
| ResNet50 | Deep residual network | 224Ã—224Ã—3 |
| InceptionV3 | Google's inception architecture | 224Ã—224Ã—3 |


### Image Classification (Lung Cancer Detection)

| Model | Description | Input Size |
|-------|-------------|------------|
| AlexNet | Classic CNN architecture | 224Ã—224Ã—3 |
| DenseNet121 | Dense connections for feature propagation | 224Ã—224Ã—3 |

---

## ğŸ” XAI Techniques

### LIME (Local Interpretable Model-agnostic Explanations)
- Perturbs superpixels to understand local decision boundaries
- Works with any model (model-agnostic)
- Shows which regions contributed to the prediction

### Grad-CAM (Gradient-weighted Class Activation Mapping)
- Uses gradients from convolutional layers
- Creates heatmaps showing important spatial regions
- Requires access to model internals

### SHAP (SHapley Additive exPlanations)
- Based on Shapley values from game theory
- Provides consistent feature attributions
- Shows positive and negative contributions

---
